{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data retrieved from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "Epoch 1/100, Training Loss: 0.7502984404563904, Validation Loss: 0.7455360889434814\n",
      "Epoch 2/100, Training Loss: 0.7363768815994263, Validation Loss: 0.7176124453544617\n",
      "Epoch 3/100, Training Loss: 0.7148601412773132, Validation Loss: 0.7052766680717468\n",
      "Epoch 4/100, Training Loss: 0.6883490085601807, Validation Loss: 0.697323203086853\n",
      "Epoch 5/100, Training Loss: 0.6660699844360352, Validation Loss: 0.6940444707870483\n",
      "Epoch 6/100, Training Loss: 0.6476608514785767, Validation Loss: 0.6925652623176575\n",
      "Epoch 7/100, Training Loss: 0.6253433227539062, Validation Loss: 0.6937960386276245\n",
      "Epoch 8/100, Training Loss: 0.618306577205658, Validation Loss: 0.6942415833473206\n",
      "Epoch 9/100, Training Loss: 0.6134709715843201, Validation Loss: 0.6945483684539795\n",
      "Epoch 10/100, Training Loss: 0.6095766425132751, Validation Loss: 0.6948521733283997\n",
      "Epoch 11/100, Training Loss: 0.6066321730613708, Validation Loss: 0.6949082016944885\n",
      "Epoch 12/100, Training Loss: 0.6044246554374695, Validation Loss: 0.6945948600769043\n",
      "Epoch 13/100, Training Loss: 0.6038504838943481, Validation Loss: 0.6940292716026306\n",
      "Epoch 14/100, Training Loss: 0.603326141834259, Validation Loss: 0.6933612823486328\n",
      "Epoch 15/100, Training Loss: 0.6041932702064514, Validation Loss: 0.6923028230667114\n",
      "Epoch 16/100, Training Loss: 0.6041316390037537, Validation Loss: 0.6915470957756042\n",
      "Epoch 17/100, Training Loss: 0.6043750047683716, Validation Loss: 0.690597653388977\n",
      "Epoch 18/100, Training Loss: 0.6043357849121094, Validation Loss: 0.6898564696311951\n",
      "Epoch 19/100, Training Loss: 0.603847086429596, Validation Loss: 0.6893416047096252\n",
      "Epoch 20/100, Training Loss: 0.6021429896354675, Validation Loss: 0.6892310976982117\n",
      "Epoch 21/100, Training Loss: 0.5995354652404785, Validation Loss: 0.6895418167114258\n",
      "Epoch 22/100, Training Loss: 0.595698893070221, Validation Loss: 0.6903252601623535\n",
      "Epoch 23/100, Training Loss: 0.5917537808418274, Validation Loss: 0.691534161567688\n",
      "Epoch 24/100, Training Loss: 0.5882346630096436, Validation Loss: 0.6930420994758606\n",
      "Epoch 25/100, Training Loss: 0.5853824019432068, Validation Loss: 0.6946372985839844\n",
      "Epoch 26/100, Training Loss: 0.5831124782562256, Validation Loss: 0.6962090730667114\n",
      "Epoch 27/100, Training Loss: 0.5818438529968262, Validation Loss: 0.6975052356719971\n",
      "Epoch 28/100, Training Loss: 0.5811439156532288, Validation Loss: 0.6984481811523438\n",
      "Epoch 29/100, Training Loss: 0.5811952352523804, Validation Loss: 0.6988441944122314\n",
      "Epoch 30/100, Training Loss: 0.5821377038955688, Validation Loss: 0.6985856890678406\n",
      "Epoch 31/100, Training Loss: 0.5838056206703186, Validation Loss: 0.6977992057800293\n",
      "Epoch 32/100, Training Loss: 0.585896909236908, Validation Loss: 0.6966737508773804\n",
      "Epoch 33/100, Training Loss: 0.5883457660675049, Validation Loss: 0.6953722238540649\n",
      "Epoch 34/100, Training Loss: 0.590596616268158, Validation Loss: 0.6941899657249451\n",
      "Epoch 35/100, Training Loss: 0.5922144055366516, Validation Loss: 0.6931704878807068\n",
      "Epoch 36/100, Training Loss: 0.5939348936080933, Validation Loss: 0.6922972202301025\n",
      "Epoch 37/100, Training Loss: 0.5959631204605103, Validation Loss: 0.691440761089325\n",
      "Epoch 38/100, Training Loss: 0.5985510349273682, Validation Loss: 0.690448522567749\n",
      "Epoch 39/100, Training Loss: 0.6018590331077576, Validation Loss: 0.6893284916877747\n",
      "Epoch 40/100, Training Loss: 0.6048091650009155, Validation Loss: 0.6882852911949158\n",
      "Epoch 41/100, Training Loss: 0.6070524454116821, Validation Loss: 0.6873913407325745\n",
      "Epoch 42/100, Training Loss: 0.6078763008117676, Validation Loss: 0.686819851398468\n",
      "Epoch 43/100, Training Loss: 0.6084101796150208, Validation Loss: 0.6865506172180176\n",
      "Epoch 44/100, Training Loss: 0.6088722348213196, Validation Loss: 0.6863845586776733\n",
      "Epoch 45/100, Training Loss: 0.6093198657035828, Validation Loss: 0.6862798929214478\n",
      "Epoch 46/100, Training Loss: 0.60956209897995, Validation Loss: 0.6861552000045776\n",
      "Epoch 47/100, Training Loss: 0.6095134019851685, Validation Loss: 0.6860774755477905\n",
      "Epoch 48/100, Training Loss: 0.6093541383743286, Validation Loss: 0.6860036253929138\n",
      "Epoch 49/100, Training Loss: 0.609179675579071, Validation Loss: 0.6859380602836609\n",
      "Epoch 50/100, Training Loss: 0.6093397736549377, Validation Loss: 0.6858636140823364\n",
      "Epoch 51/100, Training Loss: 0.6094958186149597, Validation Loss: 0.6857965588569641\n",
      "Epoch 52/100, Training Loss: 0.6101990938186646, Validation Loss: 0.6856687664985657\n",
      "Epoch 53/100, Training Loss: 0.6099579930305481, Validation Loss: 0.6858226656913757\n",
      "Epoch 54/100, Training Loss: 0.6106222867965698, Validation Loss: 0.6857515573501587\n",
      "Epoch 55/100, Training Loss: 0.6109587550163269, Validation Loss: 0.6856727600097656\n",
      "Epoch 56/100, Training Loss: 0.6112857460975647, Validation Loss: 0.6856350302696228\n",
      "Epoch 57/100, Training Loss: 0.6116330623626709, Validation Loss: 0.6855549216270447\n",
      "Epoch 58/100, Training Loss: 0.6120895147323608, Validation Loss: 0.6855244636535645\n",
      "Epoch 59/100, Training Loss: 0.6126988530158997, Validation Loss: 0.6854857802391052\n",
      "Epoch 60/100, Training Loss: 0.6131237745285034, Validation Loss: 0.6854164600372314\n",
      "Epoch 61/100, Training Loss: 0.6135629415512085, Validation Loss: 0.6853355169296265\n",
      "Epoch 62/100, Training Loss: 0.6140427589416504, Validation Loss: 0.6852508783340454\n",
      "Epoch 63/100, Training Loss: 0.6145633459091187, Validation Loss: 0.6851781010627747\n",
      "Epoch 64/100, Training Loss: 0.6150681972503662, Validation Loss: 0.6850893497467041\n",
      "Epoch 65/100, Training Loss: 0.6156205534934998, Validation Loss: 0.684992253780365\n",
      "Epoch 66/100, Training Loss: 0.616165041923523, Validation Loss: 0.6848976612091064\n",
      "Epoch 67/100, Training Loss: 0.616664469242096, Validation Loss: 0.6848004460334778\n",
      "Epoch 68/100, Training Loss: 0.6164711117744446, Validation Loss: 0.6848198771476746\n",
      "Epoch 69/100, Training Loss: 0.6177421808242798, Validation Loss: 0.6846018433570862\n",
      "Epoch 70/100, Training Loss: 0.618701159954071, Validation Loss: 0.6844586730003357\n",
      "Epoch 71/100, Training Loss: 0.619290828704834, Validation Loss: 0.6843706369400024\n",
      "Epoch 72/100, Training Loss: 0.6193287372589111, Validation Loss: 0.6843302845954895\n",
      "Epoch 73/100, Training Loss: 0.6183472871780396, Validation Loss: 0.6844057440757751\n",
      "Epoch 74/100, Training Loss: 0.619338870048523, Validation Loss: 0.6841967701911926\n",
      "Epoch 75/100, Training Loss: 0.6190899014472961, Validation Loss: 0.6841681599617004\n",
      "Epoch 76/100, Training Loss: 0.619234561920166, Validation Loss: 0.6840465664863586\n",
      "Epoch 77/100, Training Loss: 0.6189978718757629, Validation Loss: 0.6840741038322449\n",
      "Epoch 78/100, Training Loss: 0.622107744216919, Validation Loss: 0.683628261089325\n",
      "Epoch 79/100, Training Loss: 0.6220078468322754, Validation Loss: 0.6836220622062683\n",
      "Epoch 80/100, Training Loss: 0.622230052947998, Validation Loss: 0.6835609078407288\n",
      "Epoch 81/100, Training Loss: 0.6218738555908203, Validation Loss: 0.6835245490074158\n",
      "Epoch 82/100, Training Loss: 0.6211210489273071, Validation Loss: 0.6836180686950684\n",
      "Epoch 83/100, Training Loss: 0.6209999322891235, Validation Loss: 0.6835765838623047\n",
      "Epoch 84/100, Training Loss: 0.6202242374420166, Validation Loss: 0.6836422085762024\n",
      "Epoch 85/100, Training Loss: 0.6227602362632751, Validation Loss: 0.68333899974823\n",
      "Epoch 86/100, Training Loss: 0.6235836744308472, Validation Loss: 0.683207631111145\n",
      "Epoch 87/100, Training Loss: 0.6228564977645874, Validation Loss: 0.6831817030906677\n",
      "Epoch 88/100, Training Loss: 0.6215780973434448, Validation Loss: 0.68326336145401\n",
      "Epoch 89/100, Training Loss: 0.6208285689353943, Validation Loss: 0.683242678642273\n",
      "Epoch 90/100, Training Loss: 0.619235098361969, Validation Loss: 0.6834624409675598\n",
      "Epoch 91/100, Training Loss: 0.6186230182647705, Validation Loss: 0.6834574341773987\n",
      "Epoch 92/100, Training Loss: 0.6165648102760315, Validation Loss: 0.6839649677276611\n",
      "Epoch 93/100, Training Loss: 0.6168252229690552, Validation Loss: 0.6836947798728943\n",
      "Epoch 94/100, Training Loss: 0.6155386567115784, Validation Loss: 0.6839298009872437\n",
      "Epoch 95/100, Training Loss: 0.6156788468360901, Validation Loss: 0.683773398399353\n",
      "Epoch 96/100, Training Loss: 0.6145045757293701, Validation Loss: 0.684062123298645\n",
      "Epoch 97/100, Training Loss: 0.6148781776428223, Validation Loss: 0.6838231086730957\n",
      "Epoch 98/100, Training Loss: 0.6139531135559082, Validation Loss: 0.684015691280365\n",
      "Epoch 99/100, Training Loss: 0.6138181090354919, Validation Loss: 0.6839684247970581\n",
      "Epoch 100/100, Training Loss: 0.6137179732322693, Validation Loss: 0.6838963627815247\n",
      "Training Accuracy 0.6026119589805603\n",
      "Validation Accuracy 0.5732010006904602\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"water_potability.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "X = df[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values\n",
    "y = df['Potability'].values\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# Train the model\n",
    "loss_fn = nn.BCELoss()  # binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training loop\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        Xbatch = X_train[i:i + batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_train[i:i + batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = loss_fn(y_val_pred, y_val)\n",
    "    \n",
    "    # Print training and validation loss for each epoch\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "# Compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_train)\n",
    "accuracy = (y_pred.round() == y_train).float().mean()\n",
    "print(f\"Training Accuracy {accuracy}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(X_val)\n",
    "accuracy_val = (y_val_pred.round() == y_val).float().mean()\n",
    "print(f\"Validation Accuracy {accuracy_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fd5576acad3f7a858578a2aec3c3111a18ba7fcbb98d6518a6bbc5d9d4206a1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
