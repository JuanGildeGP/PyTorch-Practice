{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data retrieved from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "Epoch 1/100, Training Loss: 0.6252519488334656, Validation Loss: 0.6949087381362915\n",
      "Epoch 2/100, Training Loss: 0.6232001781463623, Validation Loss: 0.6830338835716248\n",
      "Epoch 3/100, Training Loss: 0.593116819858551, Validation Loss: 0.6758010387420654\n",
      "Epoch 4/100, Training Loss: 0.554042398929596, Validation Loss: 0.6729598641395569\n",
      "Epoch 5/100, Training Loss: 0.573720395565033, Validation Loss: 0.6699259877204895\n",
      "Epoch 6/100, Training Loss: 0.5808222889900208, Validation Loss: 0.6684656739234924\n",
      "Epoch 7/100, Training Loss: 0.5726479291915894, Validation Loss: 0.6705564856529236\n",
      "Epoch 8/100, Training Loss: 0.579971194267273, Validation Loss: 0.6717203855514526\n",
      "Epoch 9/100, Training Loss: 0.5823435187339783, Validation Loss: 0.6728173494338989\n",
      "Epoch 10/100, Training Loss: 0.5906294584274292, Validation Loss: 0.6752678155899048\n",
      "Epoch 11/100, Training Loss: 0.5963394045829773, Validation Loss: 0.6758067607879639\n",
      "Epoch 12/100, Training Loss: 0.5957093834877014, Validation Loss: 0.6760651469230652\n",
      "Epoch 13/100, Training Loss: 0.5960044860839844, Validation Loss: 0.677117645740509\n",
      "Epoch 14/100, Training Loss: 0.5983559489250183, Validation Loss: 0.6778681874275208\n",
      "Epoch 15/100, Training Loss: 0.6001735925674438, Validation Loss: 0.6782059669494629\n",
      "Epoch 16/100, Training Loss: 0.6010765433311462, Validation Loss: 0.679021954536438\n",
      "Epoch 17/100, Training Loss: 0.6025970578193665, Validation Loss: 0.6793875694274902\n",
      "Epoch 18/100, Training Loss: 0.6077284216880798, Validation Loss: 0.6794806122779846\n",
      "Epoch 19/100, Training Loss: 0.611218273639679, Validation Loss: 0.6800416111946106\n",
      "Epoch 20/100, Training Loss: 0.614513099193573, Validation Loss: 0.680413007736206\n",
      "Epoch 21/100, Training Loss: 0.6189572215080261, Validation Loss: 0.681172251701355\n",
      "Epoch 22/100, Training Loss: 0.6198972463607788, Validation Loss: 0.6813094615936279\n",
      "Epoch 23/100, Training Loss: 0.6209550499916077, Validation Loss: 0.6813424825668335\n",
      "Epoch 24/100, Training Loss: 0.621919572353363, Validation Loss: 0.6814923286437988\n",
      "Epoch 25/100, Training Loss: 0.6223832368850708, Validation Loss: 0.6809159517288208\n",
      "Epoch 26/100, Training Loss: 0.6238569617271423, Validation Loss: 0.6809162497520447\n",
      "Epoch 27/100, Training Loss: 0.6243578195571899, Validation Loss: 0.6807265877723694\n",
      "Epoch 28/100, Training Loss: 0.6250960230827332, Validation Loss: 0.6806172728538513\n",
      "Epoch 29/100, Training Loss: 0.6250792145729065, Validation Loss: 0.680428147315979\n",
      "Epoch 30/100, Training Loss: 0.6266162395477295, Validation Loss: 0.6800559759140015\n",
      "Epoch 31/100, Training Loss: 0.6266493201255798, Validation Loss: 0.6798277497291565\n",
      "Epoch 32/100, Training Loss: 0.6277564167976379, Validation Loss: 0.679699182510376\n",
      "Epoch 33/100, Training Loss: 0.6261457204818726, Validation Loss: 0.6793591380119324\n",
      "Epoch 34/100, Training Loss: 0.6277294754981995, Validation Loss: 0.6792490482330322\n",
      "Epoch 35/100, Training Loss: 0.6265321969985962, Validation Loss: 0.6791253685951233\n",
      "Epoch 36/100, Training Loss: 0.6245065927505493, Validation Loss: 0.6789746284484863\n",
      "Epoch 37/100, Training Loss: 0.6221156120300293, Validation Loss: 0.6788358688354492\n",
      "Epoch 38/100, Training Loss: 0.6214517951011658, Validation Loss: 0.6788063049316406\n",
      "Epoch 39/100, Training Loss: 0.6172738075256348, Validation Loss: 0.6785852313041687\n",
      "Epoch 40/100, Training Loss: 0.6155521869659424, Validation Loss: 0.6784922480583191\n",
      "Epoch 41/100, Training Loss: 0.615766167640686, Validation Loss: 0.6785944104194641\n",
      "Epoch 42/100, Training Loss: 0.6135318875312805, Validation Loss: 0.6782860159873962\n",
      "Epoch 43/100, Training Loss: 0.614346444606781, Validation Loss: 0.678486704826355\n",
      "Epoch 44/100, Training Loss: 0.6149628162384033, Validation Loss: 0.6783876419067383\n",
      "Epoch 45/100, Training Loss: 0.6137459874153137, Validation Loss: 0.6783370971679688\n",
      "Epoch 46/100, Training Loss: 0.6140848398208618, Validation Loss: 0.678568959236145\n",
      "Epoch 47/100, Training Loss: 0.6127451658248901, Validation Loss: 0.6784495115280151\n",
      "Epoch 48/100, Training Loss: 0.6117354035377502, Validation Loss: 0.6785413026809692\n",
      "Epoch 49/100, Training Loss: 0.6113435626029968, Validation Loss: 0.6788214445114136\n",
      "Epoch 50/100, Training Loss: 0.6093239188194275, Validation Loss: 0.6786932349205017\n",
      "Epoch 51/100, Training Loss: 0.6060712337493896, Validation Loss: 0.6789906024932861\n",
      "Epoch 52/100, Training Loss: 0.6013714671134949, Validation Loss: 0.6790828108787537\n",
      "Epoch 53/100, Training Loss: 0.596825122833252, Validation Loss: 0.6792804002761841\n",
      "Epoch 54/100, Training Loss: 0.5939239859580994, Validation Loss: 0.6792652010917664\n",
      "Epoch 55/100, Training Loss: 0.591282308101654, Validation Loss: 0.6794784665107727\n",
      "Epoch 56/100, Training Loss: 0.5900763869285583, Validation Loss: 0.6800192594528198\n",
      "Epoch 57/100, Training Loss: 0.5881903767585754, Validation Loss: 0.6803334951400757\n",
      "Epoch 58/100, Training Loss: 0.5872060656547546, Validation Loss: 0.6807180643081665\n",
      "Epoch 59/100, Training Loss: 0.5865093469619751, Validation Loss: 0.6812916994094849\n",
      "Epoch 60/100, Training Loss: 0.58587247133255, Validation Loss: 0.6814866065979004\n",
      "Epoch 61/100, Training Loss: 0.585182249546051, Validation Loss: 0.6820403337478638\n",
      "Epoch 62/100, Training Loss: 0.5848557353019714, Validation Loss: 0.6822798252105713\n",
      "Epoch 63/100, Training Loss: 0.5845193266868591, Validation Loss: 0.6824893355369568\n",
      "Epoch 64/100, Training Loss: 0.5846425890922546, Validation Loss: 0.6830200552940369\n",
      "Epoch 65/100, Training Loss: 0.5838784575462341, Validation Loss: 0.6834288835525513\n",
      "Epoch 66/100, Training Loss: 0.5846033692359924, Validation Loss: 0.6836409568786621\n",
      "Epoch 67/100, Training Loss: 0.5847172737121582, Validation Loss: 0.6839781403541565\n",
      "Epoch 68/100, Training Loss: 0.5843068361282349, Validation Loss: 0.6841273307800293\n",
      "Epoch 69/100, Training Loss: 0.5846930146217346, Validation Loss: 0.6843228340148926\n",
      "Epoch 70/100, Training Loss: 0.5851351022720337, Validation Loss: 0.6845518946647644\n",
      "Epoch 71/100, Training Loss: 0.5853808522224426, Validation Loss: 0.6847466826438904\n",
      "Epoch 72/100, Training Loss: 0.5848161578178406, Validation Loss: 0.6850308179855347\n",
      "Epoch 73/100, Training Loss: 0.5862134099006653, Validation Loss: 0.6852728724479675\n",
      "Epoch 74/100, Training Loss: 0.5864752531051636, Validation Loss: 0.6853590607643127\n",
      "Epoch 75/100, Training Loss: 0.5862512588500977, Validation Loss: 0.6856678128242493\n",
      "Epoch 76/100, Training Loss: 0.5872572660446167, Validation Loss: 0.6858440041542053\n",
      "Epoch 77/100, Training Loss: 0.584226131439209, Validation Loss: 0.6858780980110168\n",
      "Epoch 78/100, Training Loss: 0.5879785418510437, Validation Loss: 0.6860844492912292\n",
      "Epoch 79/100, Training Loss: 0.5879718065261841, Validation Loss: 0.6862689852714539\n",
      "Epoch 80/100, Training Loss: 0.5884108543395996, Validation Loss: 0.6864196062088013\n",
      "Epoch 81/100, Training Loss: 0.5885513424873352, Validation Loss: 0.686616063117981\n",
      "Epoch 82/100, Training Loss: 0.5887015461921692, Validation Loss: 0.6867541074752808\n",
      "Epoch 83/100, Training Loss: 0.5891607999801636, Validation Loss: 0.6866530179977417\n",
      "Epoch 84/100, Training Loss: 0.5895893573760986, Validation Loss: 0.6867627501487732\n",
      "Epoch 85/100, Training Loss: 0.5887908339500427, Validation Loss: 0.6867673993110657\n",
      "Epoch 86/100, Training Loss: 0.5901541113853455, Validation Loss: 0.6866969466209412\n",
      "Epoch 87/100, Training Loss: 0.5911856293678284, Validation Loss: 0.6869231462478638\n",
      "Epoch 88/100, Training Loss: 0.5911425352096558, Validation Loss: 0.6867121458053589\n",
      "Epoch 89/100, Training Loss: 0.5919127464294434, Validation Loss: 0.6866914629936218\n",
      "Epoch 90/100, Training Loss: 0.5914872884750366, Validation Loss: 0.6865853667259216\n",
      "Epoch 91/100, Training Loss: 0.5917280912399292, Validation Loss: 0.6861236691474915\n",
      "Epoch 92/100, Training Loss: 0.592835545539856, Validation Loss: 0.6863861680030823\n",
      "Epoch 93/100, Training Loss: 0.5930910110473633, Validation Loss: 0.6864161491394043\n",
      "Epoch 94/100, Training Loss: 0.5938084721565247, Validation Loss: 0.686104953289032\n",
      "Epoch 95/100, Training Loss: 0.5942955613136292, Validation Loss: 0.685714066028595\n",
      "Epoch 96/100, Training Loss: 0.5959134697914124, Validation Loss: 0.6858901977539062\n",
      "Epoch 97/100, Training Loss: 0.5945749282836914, Validation Loss: 0.6857362389564514\n",
      "Epoch 98/100, Training Loss: 0.596076488494873, Validation Loss: 0.6855139136314392\n",
      "Epoch 99/100, Training Loss: 0.5974556803703308, Validation Loss: 0.6854156255722046\n",
      "Epoch 100/100, Training Loss: 0.5986002683639526, Validation Loss: 0.6851765513420105\n",
      "Training Accuracy 0.6057214140892029\n",
      "Validation Accuracy 0.5756824016571045\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/water_potability.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "X = df[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values\n",
    "y = df['Potability'].values\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# Train the model\n",
    "loss_fn = nn.BCELoss()  # binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training loop\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        Xbatch = X_train[i:i + batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_train[i:i + batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = loss_fn(y_val_pred, y_val)\n",
    "    \n",
    "    # Print training and validation loss for each epoch\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "# Compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_train)\n",
    "accuracy = (y_pred.round() == y_train).float().mean()\n",
    "print(f\"Training Accuracy {accuracy}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(X_val)\n",
    "accuracy_val = (y_val_pred.round() == y_val).float().mean()\n",
    "print(f\"Validation Accuracy {accuracy_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fd5576acad3f7a858578a2aec3c3111a18ba7fcbb98d6518a6bbc5d9d4206a1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
